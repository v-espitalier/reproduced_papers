{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum optical reservoir computing powered by boson sampling\n",
    "\n",
    "This approach builds upon prior work by [Sakurai and al.](https://opg.optica.org/opticaq/abstract.cfm?URI=opticaq-3-3-238).\n",
    "\n",
    "This notebook demonstrates the **Quantum Optical Reservoir Computing (QORC)** experiment using the _MerLin_ quantum machine learning framework. The code replicates the performance results of quantum feature-based classification on the MNIST dataset, showcasing the proof-of-concept benefits of quantum reservoirs for machine learning tasks.\n",
    "\n",
    "QORC leverages **boson sampling** to compute highly non-linear quantum features from input data. These features, generated through photonic circuits, capture complex patterns that are difficult to extract classically. A classical linear layer is then trained on these quantum-encoded features, forming a hybrid quantum-classical classifier. This approach demonstrates how quantum reservoirs can outperform classical feature extraction by leveraging the exponential expressivity of photonic circuits, enabling enhanced classification performance on complex datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parameters definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T20:44:33.420179Z",
     "start_time": "2025-08-29T20:44:33.409380Z"
    }
   },
   "outputs": [],
   "source": [
    "# Main parameters\n",
    "n_photons = 3\n",
    "n_modes = 20\n",
    "seed = 42\n",
    "\n",
    "# Dataset parameters\n",
    "fold_index = 0\n",
    "n_fold = 5\n",
    "\n",
    "# Training parameters\n",
    "n_epochs = 2\n",
    "#n_epochs = 100\n",
    "batch_size = 100\n",
    "learning_rate = 0.05\n",
    "reduce_lr_patience = 10\n",
    "reduce_lr_factor = 0.5\n",
    "num_workers = 0\n",
    "pin_memory = False\n",
    "f_out_weights= \"f_weights_out.pth\"\n",
    "\n",
    "# Other parameters\n",
    "b_no_bunching = True\n",
    "b_use_tensorboard = False\n",
    "device_name = \"cpu\"\n",
    "outdir = \"outdir\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Parameters explanation\n",
    "\n",
    "#### Photonic Circuit Parameters\n",
    "\n",
    "- **n_modes** : Defines the number of modes in the photonic circuit, analogous to the width of a data bus in classical computing. Photons propagate through linear optical components (e.g., phase shifters and beamsplitters).\n",
    "\n",
    "- **n_photons** :\n",
    "  Number of photons injected into the circuit. The expressiveness of the quantum layer grows exponentially with this parameter, as it directly determines the dimensionality of the output spaceâ€”specifically, the number of possible Fock states (photon number distributions across modes).\n",
    "\n",
    "- **b_no_bunching** :\n",
    "  Enforces the constraint that at most one photon is detected per mode (output channel). This simplifies computation by excluding photon bunching cases. It is a valid approximation when the number of photons squared (**n_photons^2**) is significantly smaller than the number of modes (n_modes), ensuring that the probability of bunching remains negligible\n",
    "\n",
    "---\n",
    "\n",
    "#### Reproducibility\n",
    "- **seed** :\n",
    "  Controls the reproducibility of the experiment by fixing random number generators for Python, NumPy, PyTorch, and CUDA. If negative, then RNGs are not seeded.\n",
    "\n",
    "---\n",
    "\n",
    "#### Data Splitting\n",
    "- **fold_index** :\n",
    "  Indicates which fold of the dataset is used for validation during cross-validation.\n",
    "\n",
    "- **n_fold** :\n",
    "  Specifies the number of folds for cross-validation, determining how the dataset is split into training and validation sets.\n",
    "\n",
    "---\n",
    "\n",
    "#### Training Parameters\n",
    "- **n_epochs** :\n",
    "  Sets the number of training epochs (full passes through the dataset).\n",
    "\n",
    "- **batch_size** :\n",
    "  Number of images processed simultaneously in each stochastic gradient descent iteration.\n",
    "\n",
    "- **learning_rate** :\n",
    "  Step size for parameter updates. Higher values speed up learning but may reduce stability, while lower values ensure stability but may slow convergence.\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Librairies loading & logging configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T20:52:29.135845Z",
     "start_time": "2025-08-29T20:52:29.121775Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime as dt\n",
    "import math\n",
    "import random\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import perceval as pcvl\n",
    "import merlin as ML\n",
    "from merlin.datasets.mnist_digits import get_data_train_original, get_data_test_original\n",
    "\n",
    "from lib.lib_datasets import (\n",
    "    tensor_dataset,\n",
    "    get_dataloader,\n",
    "    split_fold_numpy,\n",
    ")\n",
    "from lib.lib_learning import get_device, model_eval, model_fit\n",
    "from implementation import configure_logging\n",
    "\n",
    "\n",
    "\n",
    "##################################\n",
    "# Activate logging\n",
    "configure_logging(\"info\")  # basic console logging before config is resolved\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Prepare output directory with timestamped run folder\n",
    "timestamp = dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "base_out = Path(outdir)\n",
    "run_dir = base_out / f\"run_{timestamp}\"\n",
    "run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Configure logging based on resolved config and add file handler in the run directory\n",
    "configure_logging(\"info\", run_dir / \"run.log\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MNIST Dataset loading from MerLin API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T20:39:44.271567Z",
     "start_time": "2025-08-29T20:36:03.254559Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 11:38:05 | INFO | __main__ | Call to qorc_encoding_and_linear_training: n_photons=3, n_modes=20, run_seed=42, fold_index=0\n",
      "2025-10-09 11:38:05 | INFO | __main__ | Loading MNIST data...\n",
      "2025-10-09 11:38:06 | INFO | __main__ | Datasets sizes:\n",
      "2025-10-09 11:38:06 | INFO | __main__ | (48000,)\n",
      "2025-10-09 11:38:06 | INFO | __main__ | (48000, 784)\n",
      "2025-10-09 11:38:06 | INFO | __main__ | (12000,)\n",
      "2025-10-09 11:38:06 | INFO | __main__ | (12000, 784)\n",
      "2025-10-09 11:38:06 | INFO | __main__ | (10000,)\n",
      "2025-10-09 11:38:06 | INFO | __main__ | (10000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "storage_device = torch.device(\"cpu\")\n",
    "compute_device = get_device(device_name)\n",
    "\n",
    "run_seed = seed\n",
    "if run_seed >= 0:\n",
    "    # Seeding to control the random generators\n",
    "    random.seed(run_seed)\n",
    "    np.random.seed(run_seed)\n",
    "    torch.manual_seed(seed=run_seed)\n",
    "    torch.cuda.manual_seed_all(seed=run_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "torch.use_deterministic_algorithms(mode=False)\n",
    "\n",
    "logger.info(\n",
    "    \"Call to qorc_encoding_and_linear_training: n_photons={}, n_modes={}, run_seed={}, fold_index={}\".format(\n",
    "        n_photons, n_modes, run_seed, fold_index\n",
    "    )\n",
    ")\n",
    "time_t1 = time.time()\n",
    "\n",
    "logger.info(\"Loading MNIST data...\")\n",
    "val_train_data, val_train_label, _ = get_data_train_original()\n",
    "val_train_data = (\n",
    "    val_train_data.reshape(val_train_data.shape[0], -1).astype(np.float32) / 255.0\n",
    ")\n",
    "\n",
    "val_label, val_data, train_label, train_data = split_fold_numpy(\n",
    "    val_train_label, val_train_data, n_fold, fold_index, split_seed=run_seed\n",
    ")\n",
    "\n",
    "test_data, test_label, _ = get_data_test_original()\n",
    "test_data = test_data.reshape(test_data.shape[0], -1).astype(np.float32) / 255.0\n",
    "n_pixels = 28 * 28  # MNIST images size\n",
    "n_classes = 10  # 10 classes, one for each figure\n",
    "\n",
    "## TODO: Tester le contenu des donnÃ©es\n",
    "## Show some MNIST images\n",
    "## HEAD sur les csv de MNIST\n",
    "logger.info(\"Datasets sizes:\")\n",
    "logger.info(train_label.shape)  # (48000,)\n",
    "logger.info(train_data.shape)  # (48000, 784)\n",
    "logger.info(val_label.shape)  # (12000,)\n",
    "logger.info(val_data.shape)  # (12000, 784)\n",
    "logger.info(test_label.shape)  # (10000,)\n",
    "logger.info(test_data.shape)  # (10000, 784)\n",
    "\n",
    "# Afficher les 5 premiÃ¨res images du train set\n",
    "plt.figure(figsize=(12, 3))  # Largeur x Hauteur en pouces\n",
    "for i in range(5):\n",
    "    # Remodeler les donnÃ©es aplaties (784,) en image 28x28\n",
    "    image = train_data[i].reshape(28, 28)\n",
    "    plt.subplot(1, 5, i + 1)  # 1 ligne, 5 colonnes, position i+1\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f\"Label: {train_label[i]}\")\n",
    "    plt.axis('off')  # Masquer les axes\n",
    "plt.tight_layout()  # Ajuste l'espacement entre les images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Definition of the Quantum Circuit and the Quantum Layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Circuit\n",
    "\n",
    "In the QORC experiment, the architecture comprises a pre-circuitâ€”an M-mode random Haar-uniform interferometer with N single-photon inputsâ€”that generates a high-dimensional photonic resource state by distributing the photons across the modes. This state is then modulated by a column of phase shifters, which encode the classical input data (e.g., PCA-transformed features) into the quantum circuit by adjusting the optical phases. The processed state is further transformed by a reservoir, implemented as a second M-mode random interferometer (often identical to the pre-circuit), which enhances the non-linearity of the quantum features. The final output, a distribution over Fock states, serves as a highly expressive feature vector for subsequent classical processing, such as linear classification. The combination of the pre-circuit, phase shifters, and reservoir enables the mapping of input data into a complex quantum feature space, where the dimensionality scales combinatorially with the number of photons and modes, offering a potential advantage over classical feature extraction methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unitary = pcvl.Matrix.random_unitary(n_modes)  # Haar-uniform unitary sampling\n",
    "precircuit = pcvl.Unitary(unitary)\n",
    "reservoir = interferometer_1.copy()\n",
    "\n",
    "# Input Phase Shifters\n",
    "c_var = pcvl.Circuit(n_modes)\n",
    "for i in range(n_modes):\n",
    "    px = pcvl.P(f\"px{i + 1}\")\n",
    "    port_range = i\n",
    "    c_var.add(port_range, pcvl.PS(px))\n",
    "\n",
    "qorc_circuit = precircuit // c_var // reservoir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Layer\n",
    "The input data is encoded into the phase parameters of the intermediate phase shifters, modulating the optical modes of the photonic circuit. The quantum layer's output consists of Fock-state probabilities (ML.OutputMappingStrategy.NONE), measured via coincidence detection at the circuit's output ports. These probabilities form a high-dimensional, non-linear feature vector, which is then used as input for classical classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T21:27:43.213442Z",
     "start_time": "2025-08-29T21:21:26.007062Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 10:55:29 | INFO | __main__ | MerLin QuantumLayer creation:\n",
      "2025-10-09 10:55:29 | INFO | __main__ | QuantumLayer(custom_circuit, input_size=20, output_size=1140)\n"
     ]
    }
   ],
   "source": [
    "assert n_photons <= n_modes, (\n",
    "    \"Error with photons_input_mode: Too many photons versus modes.\"\n",
    ")\n",
    "step = (n_modes - 1) / (n_photons - 1) if n_photons > 1 else 0\n",
    "qorc_input_state = [0] * n_modes\n",
    "for k in range(n_photons):\n",
    "    index = int(round(k * step))\n",
    "    qorc_input_state[index] = 1\n",
    "\n",
    "params_prefix = [\"px\"]\n",
    "\n",
    "if b_no_bunching:\n",
    "    qorc_output_size = math.comb(n_modes, n_photons)\n",
    "else:\n",
    "    qorc_output_size = math.comb(n_photons + n_modes - 1, n_photons)\n",
    "\n",
    "logger.info(\"MerLin QuantumLayer creation:\")\n",
    "qorc_quantum_layer = ML.QuantumLayer(\n",
    "    input_size=n_modes,  # Nb input features = nb modes\n",
    "    output_size=qorc_output_size,  # Nb output classes = nb modes\n",
    "    circuit=qorc_circuit,  # QORC quantum circuit\n",
    "    trainable_parameters=[],  # Circuit is not trainable\n",
    "    input_parameters=params_prefix,  # Input encoding parameters\n",
    "    input_state=qorc_input_state,  # Initial photon state\n",
    "    output_mapping_strategy=ML.OutputMappingStrategy.NONE,  # Output: Get all Fock states probas\n",
    "    # See: https://merlinquantum.ai/user_guide/output_mappings.html\n",
    "    no_bunching=b_no_bunching,\n",
    "    device=torch.device(device_name),\n",
    ")\n",
    "logger.info(str(qorc_quantum_layer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Quantum features computation\n",
    "First, **PCA (Principal Component Analysis)** is applied to reduce the dimensionality of the input data, matching it to the number of modes in the quantum circuit. The resulting PCA components are then normalized using a **global min-max scaling**, ensuring compatibility with the phase shifters in the MerLin framework, which require bounded input values (to the range [0, 1]). After encoding the normalized data with the quantm layer, the output Fock-state probabilities are further standardized using a **StandardScaler**. This final normalization step improves the convergence and performance of the subsequent **linear classification layer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 10:57:36 | INFO | __main__ | Creation of the encoder of the quantum reservoir...\n",
      "2025-10-09 10:57:36 | INFO | __main__ | Quantum features size: 1140\n",
      "2025-10-09 10:57:36 | INFO | __main__ | Encoding of the PCA comps to quantum features...\n",
      "2025-10-09 10:57:44 | INFO | __main__ | Encoding over.\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Creation of the encoder of the quantum reservoir...\")\n",
    "\n",
    "# 1) PCA Components computation\n",
    "pca = PCA(n_components=n_modes)\n",
    "train_data_pca = pca.fit_transform(train_data)\n",
    "val_data_pca = pca.transform(val_data)\n",
    "test_data_pca = pca.transform(test_data)\n",
    "\n",
    "# 2) PCA comp normalization (to [0, 1] (global min/max) )\n",
    "pca_train_global_min = train_data_pca.min()\n",
    "pca_train_global_max = train_data_pca.max()\n",
    "\n",
    "def normalize_global_min_max(data, global_min, global_max):\n",
    "    epsilon = 1e-8  # Avoid zero division\n",
    "    return (data - global_min) / (global_max - global_min + epsilon)\n",
    "\n",
    "train_data_pca_norm = normalize_global_min_max(\n",
    "    train_data_pca, pca_train_global_min, pca_train_global_max\n",
    ")\n",
    "val_data_pca_norm = normalize_global_min_max(\n",
    "    val_data_pca, pca_train_global_min, pca_train_global_max\n",
    ")\n",
    "test_data_pca_norm = normalize_global_min_max(\n",
    "    test_data_pca, pca_train_global_min, pca_train_global_max\n",
    ")\n",
    "\n",
    "logger.info(\"Quantum features size: {}\".format(qorc_output_size))\n",
    "logger.info(\"Encoding of the PCA comps to quantum features...\")\n",
    "time_t2 = time.time()\n",
    "train_data_qorc = qorc_quantum_layer(\n",
    "    torch.tensor(train_data_pca_norm, dtype=torch.float32, device=compute_device)\n",
    ")\n",
    "val_data_qorc = qorc_quantum_layer(\n",
    "    torch.tensor(val_data_pca_norm, dtype=torch.float32, device=compute_device)\n",
    ")\n",
    "test_data_qorc = qorc_quantum_layer(\n",
    "    torch.tensor(test_data_pca_norm, dtype=torch.float32, device=compute_device)\n",
    ")\n",
    "logger.info(\"Encoding over.\")\n",
    "time_t3 = time.time()\n",
    "\n",
    "# 4) Quantum features normalization (standard_scaler)\n",
    "qorc_train_mean = train_data_qorc.detach().mean(dim=0)\n",
    "qorc_train_std = train_data_qorc.detach().std(dim=0)\n",
    "\n",
    "def normalize_standard_scaler(data, mean, std):\n",
    "    epsilon = 1e-8  # Avoid zero division\n",
    "    return (data - mean) / (std + epsilon)\n",
    "\n",
    "train_data_qorc_norm = normalize_standard_scaler(\n",
    "    train_data_qorc, qorc_train_mean, qorc_train_std\n",
    ")\n",
    "val_data_qorc_norm = normalize_standard_scaler(\n",
    "    val_data_qorc, qorc_train_mean, qorc_train_std\n",
    ")\n",
    "test_data_qorc_norm = normalize_standard_scaler(\n",
    "    test_data_qorc, qorc_train_mean, qorc_train_std\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Classical SSL Training for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T21:00:56.614353Z",
     "start_time": "2025-08-29T20:57:24.903483Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 10:57:54 | INFO | __main__ | train dataset len: 48000\n",
      "2025-10-09 10:57:54 | INFO | __main__ | val dataset len  : 12000\n",
      "2025-10-09 10:57:54 | INFO | __main__ | test dataset len : 10000\n",
      "2025-10-09 10:57:54 | INFO | __main__ | train loader len: 480\n",
      "2025-10-09 10:57:54 | INFO | __main__ | val loader len  : 120\n",
      "2025-10-09 10:57:54 | INFO | __main__ | test loader len : 100\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float32\n",
    "all_train_data = torch.cat(\n",
    "    (\n",
    "        torch.tensor(train_data, dtype=dtype, device=compute_device),\n",
    "        train_data_qorc_norm,\n",
    "    ),\n",
    "    dim=1,\n",
    ")\n",
    "all_val_data = torch.cat(\n",
    "    (\n",
    "        torch.tensor(val_data, dtype=dtype, device=compute_device),\n",
    "        val_data_qorc_norm,\n",
    "    ),\n",
    "    dim=1,\n",
    ")\n",
    "all_test_data = torch.cat(\n",
    "    (\n",
    "        torch.tensor(test_data, dtype=dtype, device=compute_device),\n",
    "        test_data_qorc_norm,\n",
    "    ),\n",
    "    dim=1,\n",
    ")\n",
    "\n",
    "# Datasets\n",
    "ds_train = tensor_dataset(\n",
    "    all_train_data,\n",
    "    train_label,\n",
    "    storage_device,\n",
    "    dtype=torch.float32,\n",
    "    transform=None,\n",
    "    n_side_pixels=28,\n",
    ")\n",
    "ds_val = tensor_dataset(\n",
    "    all_val_data, val_label, storage_device, dtype=torch.float32\n",
    ")\n",
    "ds_test = tensor_dataset(\n",
    "    all_test_data, test_label, storage_device, dtype=torch.float32\n",
    ")\n",
    "\n",
    "logger.info(\"train dataset len: {}\".format(len(ds_train)))\n",
    "logger.info(\"val dataset len  : {}\".format(len(ds_val)))\n",
    "logger.info(\"test dataset len : {}\".format(len(ds_test)))\n",
    "\n",
    "# Dataloaders\n",
    "shuffle_train = True\n",
    "shuffle_test = False\n",
    "train_loader = get_dataloader(\n",
    "    ds_train, batch_size, shuffle_train, num_workers, pin_memory, run_seed\n",
    ")\n",
    "val_loader = get_dataloader(\n",
    "    ds_val, batch_size, shuffle_test, num_workers, pin_memory, run_seed\n",
    ")\n",
    "test_loader = get_dataloader(\n",
    "    ds_test, batch_size, shuffle_test, num_workers, pin_memory, run_seed\n",
    ")\n",
    "\n",
    "logger.info(\"train loader len: {}\".format(len(train_loader)))\n",
    "logger.info(\"val loader len  : {}\".format(len(val_loader)))\n",
    "logger.info(\"test loader len : {}\".format(len(test_loader)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training: Model definition (linear layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T21:09:06.454017Z",
     "start_time": "2025-08-29T21:02:52.172014Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 10:57:58 | INFO | __main__ | Prepare the linear classifier\n",
      "2025-10-09 10:57:58 | INFO | __main__ | n_model_input_features: 1924\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Prepare the linear classifier\")\n",
    "\n",
    "n_model_input_features = n_pixels + qorc_output_size\n",
    "logger.info(\"n_model_input_features: {}\".format(n_model_input_features))\n",
    "linear = nn.Linear(\n",
    "    n_model_input_features, n_classes, bias=True, device=compute_device\n",
    ")\n",
    "\n",
    "nn.init.xavier_uniform_(linear.weight)  # Xavier uniforme init (Glorot)\n",
    "nn.init.zeros_(linear.bias)\n",
    "model = linear\n",
    "model.to(compute_device)\n",
    "model.train()\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training of the linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T21:12:24.847196Z",
     "start_time": "2025-08-29T21:12:24.836279Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 10:58:07 | INFO | __main__ | Evaluation before training (on test set)\n",
      "2025-10-09 10:58:07 | INFO | __main__ | 100/100 - 0s - loss: 2.6531 - accuracy: 0.1244\n",
      "2025-10-09 10:58:07 | INFO | __main__ | Beginning of training\n",
      "2025-10-09 10:58:10 | INFO | __main__ | Call model_fit(), with 19250 parameters to train.\n",
      "2025-10-09 10:58:10 | INFO | __main__ | tag heure: 2025-10-09_10:58:10 (1760000290.8356717)\n",
      "2025-10-09 10:58:12 | INFO | __main__ | Epoch 1/2\n",
      "2025-10-09 10:58:12 | INFO | __main__ | 480/480 - 1s - loss: 0.3333 - accuracy: 0.9249 - val_loss: 0.1638 - val_accuracy: 0.9516\n",
      "2025-10-09 10:58:12 | INFO | __main__ | Epoch 00001: val_loss improved from inf to 0.16382, saving model to outdir\\run_20251009-105455\\f_weights_out.pth\n",
      "2025-10-09 10:58:12 | INFO | __main__ | tag heure: 2025-10-09_10:58:12 (1760000292.577143)\n",
      "2025-10-09 10:58:14 | INFO | __main__ | Epoch 2/2\n",
      "2025-10-09 10:58:14 | INFO | __main__ | 480/480 - 1s - loss: 0.1382 - accuracy: 0.9589 - val_loss: 0.1486 - val_accuracy: 0.9547\n",
      "2025-10-09 10:58:14 | INFO | __main__ | Epoch 00002: val_loss improved from 0.16382 to 0.14855, saving model to outdir\\run_20251009-105455\\f_weights_out.pth\n",
      "2025-10-09 10:58:14 | INFO | __main__ | Training over.\n",
      "2025-10-09 10:58:14 | INFO | __main__ | Final evaluation (on test set)\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Evaluation before training (on test set)\")\n",
    "calc_accuracy = True\n",
    "printPerf = True\n",
    "_eval_test = model_eval(\n",
    "    model, test_loader, criterion, compute_device, logger, calc_accuracy, printPerf\n",
    ")\n",
    "\n",
    "logger.info(\"Beginning of training\")\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate, eps=1e-7)\n",
    "\n",
    "if b_use_tensorboard:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "    xp_name = (\n",
    "        str(n_photons)\n",
    "        + \"photons_\"\n",
    "        + str(n_modes)\n",
    "        + \"modes_\"\n",
    "        + str(run_seed)\n",
    "        + \"seed_\"\n",
    "        + str(fold_index)\n",
    "        + \"fold\"\n",
    "    )\n",
    "    tf_train_writer = SummaryWriter(\n",
    "        os.path.join(run_dir, \"runs/\" + xp_name + \"_train\")\n",
    "    )\n",
    "    tf_val_writer = SummaryWriter(os.path.join(run_dir, \"runs/\" + xp_name + \"_val\"))\n",
    "else:\n",
    "    tf_train_writer = None\n",
    "    tf_val_writer = None\n",
    "\n",
    "early_stop_patience = n_epochs\n",
    "early_stop_min_delta = 0.000001\n",
    "b_use_cosine_scheduler = False\n",
    "[\n",
    "    train_loss_history,\n",
    "    train_accuracy_history,\n",
    "    val_loss_history,\n",
    "    val_accuracy_history,\n",
    "    duree_totale,\n",
    "    best_val_epoch,\n",
    "] = model_fit(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    n_epochs,\n",
    "    os.path.join(run_dir, f_out_weights),\n",
    "    early_stop_patience,\n",
    "    early_stop_min_delta,\n",
    "    reduce_lr_patience,\n",
    "    reduce_lr_factor,\n",
    "    compute_device,\n",
    "    logger,\n",
    "    b_use_cosine_scheduler,\n",
    "    tf_train_writer=tf_train_writer,\n",
    "    tf_val_writer=tf_val_writer,\n",
    "    calc_accuracy=calc_accuracy,\n",
    ")\n",
    "\n",
    "logger.info(\"Training over.\")\n",
    "n_train_epochs = len(train_loss_history)\n",
    "time_t4 = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T21:13:22.800309Z",
     "start_time": "2025-08-29T21:13:22.738296Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 10:58:40 | INFO | __main__ | Final evaluation (on test set)\n",
      "2025-10-09 10:58:40 | INFO | __main__ | n_model_input_features: {n_model_input_features}\n",
      "2025-10-09 10:58:41 | INFO | __main__ | 480/480 - 0s - loss: 0.1245 - accuracy: 0.9619\n",
      "2025-10-09 10:58:41 | INFO | __main__ | 120/120 - 0s - loss: 0.1486 - accuracy: 0.9547\n",
      "2025-10-09 10:58:41 | INFO | __main__ | 100/100 - 0s - loss: 0.1501 - accuracy: 0.9544\n",
      "2025-10-09 10:58:41 | INFO | __main__ | Duration - Quantum layer creation: 155.52s\n",
      "2025-10-09 10:58:41 | INFO | __main__ | Duration - Quantum features encoding: 7.59s\n",
      "2025-10-09 10:58:41 | INFO | __main__ | Duration - training: 29.91s\n",
      "2025-10-09 10:58:41 | INFO | __main__ | Duration - total: 220.83s\n",
      "2025-10-09 10:58:41 | INFO | __main__ | Best val epoch: 2\n",
      "2025-10-09 10:58:41 | INFO | __main__ | Accuracies - train: 0.9619, val: 0.9547, test: 0.9544\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Final evaluation (on test set)\")\n",
    "best_state_dict = torch.load(\n",
    "    os.path.join(run_dir, f_out_weights), map_location=compute_device\n",
    ")\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(best_state_dict)\n",
    "    logger.info(\"n_model_input_features: {n_model_input_features}\")\n",
    "    [_, train_acc, _] = model_eval(\n",
    "        model,\n",
    "        train_loader,\n",
    "        criterion,\n",
    "        compute_device,\n",
    "        logger,\n",
    "        calc_accuracy,\n",
    "        printPerf,\n",
    "    )\n",
    "    train_acc = int(1000000.0 * train_acc.item()) / 1000000.0\n",
    "    [_, val_acc, _] = model_eval(\n",
    "        model,\n",
    "        val_loader,\n",
    "        criterion,\n",
    "        compute_device,\n",
    "        logger,\n",
    "        calc_accuracy,\n",
    "        printPerf,\n",
    "    )\n",
    "    val_acc = int(1000000.0 * val_acc.item()) / 1000000.0\n",
    "    [_, test_acc, _] = model_eval(\n",
    "        model,\n",
    "        test_loader,\n",
    "        criterion,\n",
    "        compute_device,\n",
    "        logger,\n",
    "        calc_accuracy,\n",
    "        printPerf,\n",
    "    )\n",
    "    test_acc = int(1000000.0 * test_acc.item()) / 1000000.0\n",
    "except RuntimeError as e:\n",
    "    logger.info(f\"Error while loading state_dict : {e}\")\n",
    "    train_acc = float(\"nan\")\n",
    "    val_acc = float(\"nan\")\n",
    "    test_acc = float(\"nan\")\n",
    "time_t5 = time.time()\n",
    "\n",
    "duration_creation_couche_quantique = int(100.0 * (time_t2 - time_t1)) / 100.0\n",
    "logger.info(\n",
    "    \"Duration - Quantum layer creation: {}s\".format(\n",
    "        duration_creation_couche_quantique\n",
    "    )\n",
    ")\n",
    "duration_calcul_quantum_features = int(100.0 * (time_t3 - time_t2)) / 100.0\n",
    "logger.info(\n",
    "    \"Duration - Quantum features encoding: {}s\".format(\n",
    "        duration_calcul_quantum_features\n",
    "    )\n",
    ")\n",
    "duration_qfeatures = (\n",
    "    duration_creation_couche_quantique + duration_calcul_quantum_features\n",
    ")\n",
    "duration_train = int(100.0 * (time_t4 - time_t3)) / 100.0\n",
    "logger.info(\"Duration - training: {}s\".format(duration_train))\n",
    "duration_totale = int(100.0 * (time_t5 - time_t1)) / 100.0\n",
    "logger.info(\"Duration - total: {}s\".format(duration_totale))\n",
    "logger.info(\"Best val epoch: {}\".format(best_val_epoch))\n",
    "\n",
    "# Afficher les accuracies aprÃ¨s apprentissage\n",
    "logger.info(\"Accuracies - train: {:.4f}, val: {:.4f}, test: {:.4f}\".format(\n",
    "    train_acc,\n",
    "    val_acc,\n",
    "    test_acc\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
