{
  "timestamp": "2025-08-28T13:51:38.525391",
  "experiment_type": "Linear_Probing",
  "pretrained_epoch": 2,
  "arguments": {
    "datadir": "./data",
    "classes": 5,
    "epochs": 5,
    "le_epochs": 100,
    "batch_size": 256,
    "ckpt_step": 1,
    "batch_norm": false,
    "loss_dim": 128,
    "temperature": 0.07,
    "width": 8,
    "merlin": true,
    "modes": 10,
    "no_bunching": true,
    "qiskit": false,
    "layers": 2,
    "q_backend": "qasm_simulator",
    "encoding": "vector",
    "q_ansatz": "sim_circ_14_half",
    "q_sweeps": 1,
    "activation": "null",
    "shots": 100,
    "save_dhs": false
  },
  "linear_evaluation": {
    "train_losses": [
      1.6012166331008988,
      1.584667175400014,
      1.5687241797544518,
      1.554669748763649,
      1.5400689949794693,
      1.5268666537440554,
      1.5143121961428194,
      1.502910558058291,
      1.4916346383338073,
      1.480079059089933,
      1.470775848140522,
      1.4607890211806005,
      1.4532980906720063,
      1.4426857537152815,
      1.4341622645757637,
      1.4250663713533052,
      1.417766852646458,
      1.4113195660162945,
      1.4045305215582555,
      1.397725178270924,
      1.3931647946639938,
      1.3869686017231064,
      1.3816571290395698,
      1.37677942368449,
      1.3700713630841703,
      1.3671442799422207,
      1.3637119841818908,
      1.356802115634996,
      1.354192575021666,
      1.3494913383406035,
      1.3488024491436628,
      1.345003079394905,
      1.3410256961170508,
      1.3355672949430895,
      1.335297133241381,
      1.33125047294461,
      1.330064709697451,
      1.3262766709133071,
      1.3271185445542237,
      1.3239097145138954,
      1.3201254241320552,
      1.3187010428126977,
      1.315364547529999,
      1.3158897307454323,
      1.3133308102889938,
      1.312087593638167,
      1.307695681951484,
      1.3089557052875052,
      1.3060108970622628,
      1.3018828253356778,
      1.3030940257773107,
      1.3018230035596965,
      1.3000294201228084,
      1.300494333311003,
      1.2974750642873802,
      1.2977386786013234,
      1.2948390476557674,
      1.2932884601914152,
      1.2956249981510395,
      1.2937424188973952,
      1.293703936192454,
      1.2942885622686269,
      1.290889394526579,
      1.2912340267580382,
      1.2857130029980017,
      1.2875665566142724,
      1.2872735930948842,
      1.2851144720096976,
      1.287160752987375,
      1.2866979794842857,
      1.2833985777533785,
      1.283870023124072,
      1.2841098837706508,
      1.2825924042536287,
      1.2831748663162699,
      1.2828277677905804,
      1.280332407781056,
      1.2810102609955534,
      1.2833261489868164,
      1.2800855788649346,
      1.278471483259785,
      1.2777731588908605,
      1.2792713629956147,
      1.2804734068257468,
      1.277315108751764,
      1.278790618083915,
      1.278045994894845,
      1.2781968901352005,
      1.277660843060941,
      1.2774918055047795,
      1.2760104841115523,
      1.2777057186681398,
      1.2775297335215978,
      1.2719124506930917,
      1.2719312790705233,
      1.2754691231007478,
      1.2750541780676161,
      1.2734616556946112,
      1.2755096092516063,
      1.271081236552219
    ],
    "val_losses": [
      1.5912798285484313,
      1.5737878799438476,
      1.5574022769927978,
      1.5417884856462478,
      1.5268282175064087,
      1.5127785384655,
      1.4989324748516082,
      1.483829253911972,
      1.4774067163467408,
      1.4648934066295625,
      1.4547681629657745,
      1.4444455087184906,
      1.4363344967365266,
      1.4282690197229386,
      1.4205411404371262,
      1.4091452479362487,
      1.4036359429359435,
      1.3940257370471953,
      1.3866725653409957,
      1.3828337162733078,
      1.3741739243268967,
      1.3694802850484848,
      1.3646346151828765,
      1.3567870765924455,
      1.3572120875120164,
      1.352080824971199,
      1.354591938853264,
      1.3503345876932145,
      1.336932960152626,
      1.3425974547863007,
      1.3343516677618026,
      1.3338312029838562,
      1.3276794731616974,
      1.3313780426979065,
      1.3231059163808823,
      1.3177586138248443,
      1.3211964547634125,
      1.3142826020717622,
      1.318632635474205,
      1.3074322640895844,
      1.314832976460457,
      1.3121664315462112,
      1.3117869049310684,
      1.303249365091324,
      1.311639553308487,
      1.307949048280716,
      1.2993030726909638,
      1.2993636459112168,
      1.3060068964958191,
      1.2962493538856505,
      1.2906891256570816,
      1.285332654416561,
      1.2888357132673263,
      1.2990093141794206,
      1.2951664239168168,
      1.2941097021102905,
      1.294259062409401,
      1.2889619171619415,
      1.2955434978008271,
      1.3035632878541947,
      1.2891199737787247,
      1.2857216417789459,
      1.2879918754100799,
      1.2942505419254302,
      1.2864527702331543,
      1.2874620109796524,
      1.2940781742334366,
      1.2820062279701232,
      1.2846410006284714,
      1.288133117556572,
      1.2838242277503014,
      1.285456508398056,
      1.2855247288942337,
      1.2940765887498855,
      1.2878591120243073,
      1.2875938415527344,
      1.288753905892372,
      1.2872549176216126,
      1.2829827845096589,
      1.2825477868318558,
      1.2896946519613266,
      1.2854351848363876,
      1.290157464146614,
      1.2773510605096816,
      1.2865740656852722,
      1.2817597329616546,
      1.2879518300294877,
      1.2871040195226668,
      1.2774181455373763,
      1.2899609863758088,
      1.272178702056408,
      1.270639744400978,
      1.2931178033351898,
      1.2888064473867415,
      1.2787498474121093,
      1.2843200385570526,
      1.2786817282438279,
      1.2841019809246064,
      1.271962758898735,
      1.2893161177635193
    ],
    "train_accuracies": [
      0.33572,
      0.44108,
      0.45496,
      0.45796,
      0.46144,
      0.46536,
      0.46792,
      0.46832,
      0.46432,
      0.46724,
      0.46664,
      0.466,
      0.46544,
      0.46736,
      0.46772,
      0.46896,
      0.46636,
      0.4686,
      0.46936,
      0.47212,
      0.47056,
      0.46984,
      0.47004,
      0.4704,
      0.47148,
      0.46632,
      0.46652,
      0.4736,
      0.47072,
      0.46936,
      0.47168,
      0.47068,
      0.47076,
      0.47328,
      0.47164,
      0.4714,
      0.47068,
      0.47188,
      0.47008,
      0.47176,
      0.47128,
      0.47116,
      0.47084,
      0.47192,
      0.46888,
      0.4698,
      0.47172,
      0.4752,
      0.473,
      0.47652,
      0.47152,
      0.47228,
      0.47028,
      0.47212,
      0.47688,
      0.4724,
      0.47324,
      0.47304,
      0.47052,
      0.47284,
      0.47056,
      0.4718,
      0.47296,
      0.47148,
      0.4778,
      0.47444,
      0.47524,
      0.47228,
      0.4706,
      0.4682,
      0.47272,
      0.47252,
      0.47176,
      0.47756,
      0.47472,
      0.47364,
      0.47544,
      0.47348,
      0.47196,
      0.47336,
      0.4748,
      0.47472,
      0.47288,
      0.47408,
      0.47296,
      0.47232,
      0.47684,
      0.4736,
      0.47476,
      0.47212,
      0.4756,
      0.47436,
      0.47232,
      0.47484,
      0.47508,
      0.47056,
      0.4692,
      0.47196,
      0.47492,
      0.47616
    ],
    "val_accuracies": [
      0.4186,
      0.444,
      0.4504,
      0.4464,
      0.4432,
      0.4356,
      0.4428,
      0.4528,
      0.4432,
      0.4382,
      0.4442,
      0.4436,
      0.443,
      0.44,
      0.4486,
      0.4448,
      0.4496,
      0.4454,
      0.4444,
      0.4464,
      0.4502,
      0.4398,
      0.4442,
      0.4484,
      0.4456,
      0.4482,
      0.4558,
      0.4432,
      0.4516,
      0.446,
      0.4406,
      0.4494,
      0.449,
      0.4456,
      0.4452,
      0.446,
      0.446,
      0.4476,
      0.4442,
      0.4506,
      0.4462,
      0.446,
      0.4418,
      0.4498,
      0.4464,
      0.4474,
      0.4486,
      0.4486,
      0.4474,
      0.4486,
      0.4494,
      0.451,
      0.4522,
      0.4474,
      0.4446,
      0.4446,
      0.4516,
      0.4478,
      0.4426,
      0.443,
      0.449,
      0.4464,
      0.4468,
      0.4494,
      0.4462,
      0.4488,
      0.4464,
      0.4488,
      0.4492,
      0.4492,
      0.448,
      0.4498,
      0.4488,
      0.4496,
      0.4466,
      0.4488,
      0.4494,
      0.4482,
      0.445,
      0.4482,
      0.4448,
      0.4454,
      0.4492,
      0.448,
      0.449,
      0.4494,
      0.4482,
      0.4458,
      0.449,
      0.4454,
      0.4486,
      0.4536,
      0.447,
      0.4468,
      0.4472,
      0.451,
      0.4524,
      0.4528,
      0.453,
      0.4474
    ],
    "final_val_accuracy": 0.4474,
    "best_val_accuracy": 0.4558
  }
}