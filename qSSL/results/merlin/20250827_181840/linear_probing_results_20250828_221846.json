{
  "timestamp": "2025-08-28T22:18:46.132238",
  "experiment_type": "Linear_Probing",
  "pretrained_epoch": 5,
  "arguments": {
    "datadir": "./data",
    "classes": 5,
    "epochs": 5,
    "le_epochs": 100,
    "batch_size": 256,
    "ckpt_step": 1,
    "batch_norm": false,
    "loss_dim": 128,
    "temperature": 0.07,
    "width": 8,
    "merlin": true,
    "modes": 10,
    "no_bunching": true,
    "qiskit": false,
    "layers": 2,
    "q_backend": "qasm_simulator",
    "encoding": "vector",
    "q_ansatz": "sim_circ_14_half",
    "q_sweeps": 1,
    "activation": "null",
    "shots": 100,
    "save_dhs": false
  },
  "linear_evaluation": {
    "train_losses": [
      1.6035114015851701,
      1.591160121620918,
      1.5791416046570759,
      1.5680696362135362,
      1.5568704416557235,
      1.5461321558271135,
      1.5362582602063004,
      1.5266051487046846,
      1.5159289459792935,
      1.5082804925587712,
      1.497752664040546,
      1.490271275749012,
      1.4818589018315684,
      1.4745359001111011,
      1.4668880153675468,
      1.4596468106824525,
      1.4538013545834287,
      1.4455276387078422,
      1.4407961040127033,
      1.4339545867880996,
      1.4277613594823955,
      1.4225807214269832,
      1.4169241281188265,
      1.411068607349785,
      1.4075095732601322,
      1.402965816308041,
      1.3990374602833573,
      1.3924522983784577,
      1.3878019050675996,
      1.3851497769355774,
      1.379927464893886,
      1.3776521926023522,
      1.371237253047982,
      1.37089504757706,
      1.36456356790601,
      1.3644213566974717,
      1.3608159562762903,
      1.3559454393630126,
      1.35491002031735,
      1.3486724143125572,
      1.3486417921221987,
      1.3455227218112167,
      1.3414467342045842,
      1.3395787276783768,
      1.3396383657747386,
      1.3344136622487281,
      1.3332676765870075,
      1.3316614530524429,
      1.3294620447012844,
      1.3281691372394562,
      1.324486101160244,
      1.3230108655228907,
      1.3191663124123398,
      1.319238929115996,
      1.3205884816695233,
      1.3159319740168902,
      1.3121836945718648,
      1.3146310539878145,
      1.313205720210562,
      1.3089838423291031,
      1.3077691306873245,
      1.3082196092119023,
      1.3073166438511439,
      1.304601724050483,
      1.3036236483223584,
      1.3006161086413326,
      1.3024741374716466,
      1.2990383828172878,
      1.2964417460013409,
      1.2957355696327832,
      1.294507054041843,
      1.294761097552825,
      1.2930925804741529,
      1.291905616619149,
      1.2929555189852813,
      1.2922778628310378,
      1.2877931327235943,
      1.2904848006306862,
      1.2875643524588372,
      1.2891358167541271,
      1.2888081201485224,
      1.2861301509701475,
      1.2839741652109184,
      1.2845673828708881,
      1.283825160897508,
      1.282876887491771,
      1.283670228354785,
      1.2807612510360018,
      1.2801372962338584,
      1.2806091193033724,
      1.2796572744846344,
      1.279769423056622,
      1.278442761119531,
      1.277187857700854,
      1.2777632511391932,
      1.2793499723989137,
      1.2767031770579669,
      1.2737400355387707,
      1.2737427329530522,
      1.2720410623112504
    ],
    "val_losses": [
      1.5940113484859466,
      1.5786533951759338,
      1.5646466732025146,
      1.5501922160387038,
      1.536255767941475,
      1.523869413137436,
      1.5137237071990968,
      1.4998122304677963,
      1.4876602560281753,
      1.4808338105678558,
      1.4666744858026504,
      1.4573007971048355,
      1.4467363357543945,
      1.4442432641983032,
      1.4363504558801652,
      1.425678899884224,
      1.4144603431224823,
      1.4144928246736526,
      1.4034771203994751,
      1.396826383471489,
      1.3879857242107392,
      1.3810170888900757,
      1.3801716953516006,
      1.373187816143036,
      1.3638037085533141,
      1.3542452841997146,
      1.357656615972519,
      1.349994918704033,
      1.3492257177829743,
      1.341475322842598,
      1.3365023583173752,
      1.3372347176074981,
      1.3270165205001831,
      1.334874874353409,
      1.3284766346216201,
      1.3209131181240081,
      1.3217088371515273,
      1.3188909888267517,
      1.3147629708051682,
      1.3069464653730392,
      1.304743793606758,
      1.2952195286750794,
      1.2973421573638917,
      1.30395288169384,
      1.300088605284691,
      1.3035872370004653,
      1.298268574476242,
      1.2927045971155167,
      1.2814610123634338,
      1.2832654058933257,
      1.2902517169713974,
      1.2837465077638626,
      1.276794496178627,
      1.285756653547287,
      1.2805463910102843,
      1.2760866045951844,
      1.2794118821620941,
      1.2812062233686448,
      1.2728619903326035,
      1.2665687471628189,
      1.2688102424144745,
      1.2779782921075822,
      1.2640666246414185,
      1.2681464016437531,
      1.2658464729785919,
      1.2726325333118438,
      1.269676923751831,
      1.263267520070076,
      1.272679117321968,
      1.2668724209070206,
      1.2649467408657074,
      1.2683214038610457,
      1.276324626803398,
      1.2614127725362778,
      1.2698158353567124,
      1.2619420915842057,
      1.256093192100525,
      1.254819530248642,
      1.2540813565254212,
      1.2653041303157806,
      1.2437036246061326,
      1.2573955178260803,
      1.257812276482582,
      1.2569382965564728,
      1.2508915543556214,
      1.25380699634552,
      1.2495910435914994,
      1.2463588565587997,
      1.2729317992925644,
      1.2585607647895813,
      1.245344227552414,
      1.246498203277588,
      1.2423105180263518,
      1.246740034222603,
      1.253175863623619,
      1.2368302911520004,
      1.243774688243866,
      1.239783638715744,
      1.2409914702177047,
      1.2373356074094772
    ],
    "train_accuracies": [
      0.28444,
      0.44296,
      0.46252,
      0.46892,
      0.47048,
      0.46896,
      0.47108,
      0.46864,
      0.474,
      0.46848,
      0.47608,
      0.47544,
      0.46996,
      0.4754,
      0.47632,
      0.47356,
      0.47408,
      0.47476,
      0.47492,
      0.47768,
      0.47452,
      0.47432,
      0.47236,
      0.4796,
      0.47632,
      0.47684,
      0.4744,
      0.47668,
      0.47788,
      0.47312,
      0.476,
      0.47612,
      0.4792,
      0.47612,
      0.47796,
      0.47652,
      0.47472,
      0.47996,
      0.47616,
      0.47996,
      0.47948,
      0.47788,
      0.4798,
      0.4786,
      0.47952,
      0.48136,
      0.4794,
      0.479,
      0.4796,
      0.4802,
      0.47704,
      0.47984,
      0.48228,
      0.48028,
      0.47572,
      0.48192,
      0.4802,
      0.4786,
      0.48376,
      0.47692,
      0.47892,
      0.47868,
      0.47652,
      0.4814,
      0.48112,
      0.48136,
      0.4796,
      0.48252,
      0.48008,
      0.4806,
      0.4828,
      0.481,
      0.48392,
      0.48516,
      0.478,
      0.47844,
      0.48112,
      0.4824,
      0.48076,
      0.4784,
      0.47908,
      0.48176,
      0.48212,
      0.48024,
      0.47788,
      0.48344,
      0.481,
      0.4812,
      0.48412,
      0.48328,
      0.47912,
      0.48176,
      0.48208,
      0.48376,
      0.47944,
      0.48328,
      0.48232,
      0.48308,
      0.484,
      0.48564
    ],
    "val_accuracies": [
      0.4634,
      0.4764,
      0.478,
      0.4632,
      0.4626,
      0.4626,
      0.462,
      0.4558,
      0.463,
      0.4568,
      0.4652,
      0.4606,
      0.4586,
      0.4612,
      0.463,
      0.4612,
      0.4684,
      0.4664,
      0.4724,
      0.4628,
      0.472,
      0.4704,
      0.4682,
      0.4678,
      0.471,
      0.4786,
      0.4678,
      0.4702,
      0.4752,
      0.4694,
      0.4782,
      0.4738,
      0.4776,
      0.4702,
      0.4732,
      0.4666,
      0.472,
      0.4794,
      0.4736,
      0.483,
      0.4784,
      0.4798,
      0.4798,
      0.474,
      0.4766,
      0.4702,
      0.4724,
      0.4752,
      0.4862,
      0.478,
      0.4788,
      0.4826,
      0.4804,
      0.4798,
      0.477,
      0.4788,
      0.4794,
      0.478,
      0.4852,
      0.4794,
      0.4828,
      0.4798,
      0.4842,
      0.48,
      0.4786,
      0.4772,
      0.48,
      0.4848,
      0.4792,
      0.4848,
      0.4794,
      0.4814,
      0.4792,
      0.4814,
      0.4842,
      0.4832,
      0.4844,
      0.4822,
      0.4836,
      0.4814,
      0.4874,
      0.4832,
      0.4816,
      0.4816,
      0.4842,
      0.4836,
      0.4868,
      0.4862,
      0.481,
      0.4826,
      0.4812,
      0.4856,
      0.485,
      0.4886,
      0.4868,
      0.4878,
      0.4834,
      0.4858,
      0.4856,
      0.4838
    ],
    "final_val_accuracy": 0.4838,
    "best_val_accuracy": 0.4886
  }
}