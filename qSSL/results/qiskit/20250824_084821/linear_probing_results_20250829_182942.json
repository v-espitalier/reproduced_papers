{
  "timestamp": "2025-08-29T18:29:42.810615",
  "experiment_type": "Linear_Probing",
  "pretrained_epoch": 5,
  "arguments": {
    "datadir": "./data",
    "classes": 5,
    "epochs": 5,
    "le_epochs": 100,
    "batch_size": 256,
    "ckpt_step": 1,
    "batch_norm": false,
    "loss_dim": 128,
    "temperature": 0.07,
    "width": 8,
    "merlin": false,
    "modes": 10,
    "no_bunching": false,
    "qiskit": true,
    "layers": 2,
    "q_backend": "qasm_simulator",
    "encoding": "vector",
    "q_ansatz": "sim_circ_14_half",
    "q_sweeps": 1,
    "activation": "null",
    "shots": 100,
    "save_dhs": false
  },
  "linear_evaluation": {
    "train_losses": [
      1.537204664580676,
      1.390634445511565,
      1.31733365691438,
      1.2802531159653956,
      1.2617261957149117,
      1.249441602400371,
      1.2463767382563378,
      1.2369766533374786,
      1.2321262937419268,
      1.2304783731090778,
      1.2306963278322804,
      1.2274485786958618,
      1.227037290529329,
      1.228285556545063,
      1.2300932383050724,
      1.227688266914718,
      1.2273139874545895,
      1.2330768242174266,
      1.2326133488392343,
      1.225993704430911,
      1.227758847937292,
      1.2287478112444585,
      1.22421168490332,
      1.2310721320765359,
      1.2279404347040215,
      1.2234695590272242,
      1.2247436685221536,
      1.2252109160228652,
      1.2274229039951248,
      1.2322618766706817,
      1.2272795542162291,
      1.2302401430752812,
      1.2300047454785328,
      1.2290159038134985,
      1.2312720199020541,
      1.22904131120565,
      1.2271971282910328,
      1.2295904530554402,
      1.232529677906815,
      1.2295148889629208,
      1.2248247265815735,
      1.2270329947374305,
      1.2303049345405734,
      1.2269149860557245,
      1.229743206379365,
      1.2295650949283523,
      1.2282473943671401,
      1.2311130172135878,
      1.2232514230572447,
      1.232177999554848,
      1.224655699364993,
      1.2242418758723201,
      1.2280482157152526,
      1.2224204522006366,
      1.226615053050372,
      1.2274168006011419,
      1.2243217540030578,
      1.2321397382385877,
      1.2305248775044266,
      1.231516915924695,
      1.225452757003356,
      1.227815874985286,
      1.2265278873394947,
      1.228559014140343,
      1.2274798817780552,
      1.2284381097676802,
      1.2287042530215517,
      1.2302031249416119,
      1.2309064986754437,
      1.2284284221882722,
      1.224640082948062,
      1.2261797822251612,
      1.2281521145178347,
      1.2280166009250952,
      1.225801560951739,
      1.227449780824233,
      1.2210054355008262,
      1.2249838600353318,
      1.2251785926672878,
      1.22961111093054,
      1.2263002353055137,
      1.2255689380120258,
      1.2282800114884669,
      1.2310430127747205,
      1.230743564513265,
      1.2275124715299022,
      1.2302003064934088,
      1.2244815601378072,
      1.2302603058669033,
      1.227216298482856,
      1.230170450648483,
      1.2306111503620536,
      1.2237765886345688,
      1.2265832983717626,
      1.2260182226190761,
      1.2313143489312153,
      1.2248795744107694,
      1.229139897896319,
      1.2269089793672368,
      1.2281648918074004
    ],
    "val_losses": [
      1.4550284028053284,
      1.3523941129446029,
      1.2996383398771285,
      1.2754437744617462,
      1.2563570946455003,
      1.25792538523674,
      1.2442201405763627,
      1.2354076325893402,
      1.259509152173996,
      1.2571182787418365,
      1.2510524332523345,
      1.2448188424110413,
      1.253098291158676,
      1.2359925776720047,
      1.2517769664525986,
      1.268388134241104,
      1.2531809985637665,
      1.2509014308452606,
      1.2438492834568025,
      1.2578492760658264,
      1.2615574657917024,
      1.2625505328178406,
      1.248955425620079,
      1.2585563898086547,
      1.2567288398742675,
      1.246068400144577,
      1.2554061830043792,
      1.2750833302736282,
      1.2600904703140259,
      1.2457665115594865,
      1.2394406452775002,
      1.256183448433876,
      1.2568439573049546,
      1.2602888137102126,
      1.2545894131064415,
      1.2482252329587937,
      1.2570497900247575,
      1.2594879537820816,
      1.263721439242363,
      1.2491544216871262,
      1.2631614625453949,
      1.2588068813085556,
      1.2515475153923035,
      1.2560842514038086,
      1.2500153809785843,
      1.2651916146278381,
      1.245459359884262,
      1.2618941366672516,
      1.2459541112184525,
      1.2601266264915467,
      1.2493664547801018,
      1.2761414170265197,
      1.2524811059236527,
      1.2716050684452056,
      1.2535515785217286,
      1.2509669005870818,
      1.2636904388666153,
      1.2607791751623154,
      1.2732479393482208,
      1.255340364575386,
      1.2437423884868621,
      1.2481383472681045,
      1.2631574124097824,
      1.2583298534154892,
      1.2450742155313492,
      1.2566011786460876,
      1.2490684166550636,
      1.2509512424468994,
      1.2699430495500565,
      1.2576393395662309,
      1.259125018119812,
      1.2594524174928665,
      1.25519158244133,
      1.2564557433128356,
      1.2558171987533568,
      1.2677898108959198,
      1.2613422214984893,
      1.272069576382637,
      1.2540642946958542,
      1.2744486302137374,
      1.2659744411706924,
      1.265194609761238,
      1.265481451153755,
      1.259417474269867,
      1.2590473651885987,
      1.2677562624216079,
      1.259141954779625,
      1.2549060344696046,
      1.2657640665769576,
      1.2505831450223923,
      1.2635481774806976,
      1.2636053085327148,
      1.2552413582801818,
      1.263828992843628,
      1.2674252539873123,
      1.2548789471387862,
      1.2467519044876099,
      1.2576417088508607,
      1.2559582322835923,
      1.265306866168976
    ],
    "train_accuracies": [
      0.29876,
      0.45728,
      0.47636,
      0.48768,
      0.48288,
      0.48812,
      0.48276,
      0.4842,
      0.48352,
      0.48724,
      0.48704,
      0.48668,
      0.48856,
      0.48896,
      0.48712,
      0.48496,
      0.48788,
      0.48308,
      0.48912,
      0.49148,
      0.49024,
      0.48928,
      0.4876,
      0.48604,
      0.48616,
      0.4916,
      0.48856,
      0.49084,
      0.48608,
      0.4842,
      0.48712,
      0.48816,
      0.48424,
      0.48536,
      0.48252,
      0.48724,
      0.48908,
      0.48872,
      0.48524,
      0.48808,
      0.48852,
      0.48464,
      0.4846,
      0.48968,
      0.48536,
      0.48624,
      0.48748,
      0.48628,
      0.48892,
      0.48252,
      0.49,
      0.48948,
      0.4856,
      0.489,
      0.48864,
      0.48456,
      0.48776,
      0.47988,
      0.48764,
      0.48564,
      0.48904,
      0.48612,
      0.48812,
      0.4888,
      0.48536,
      0.48892,
      0.48788,
      0.48756,
      0.4856,
      0.4866,
      0.49076,
      0.49044,
      0.4874,
      0.48828,
      0.49048,
      0.48752,
      0.489,
      0.4868,
      0.48812,
      0.48252,
      0.48484,
      0.4868,
      0.48576,
      0.48688,
      0.48468,
      0.4866,
      0.48512,
      0.48928,
      0.48712,
      0.4886,
      0.48832,
      0.48404,
      0.489,
      0.4864,
      0.48732,
      0.48712,
      0.49032,
      0.48788,
      0.49012,
      0.48668
    ],
    "val_accuracies": [
      0.4058,
      0.4458,
      0.4614,
      0.4608,
      0.4714,
      0.4672,
      0.4714,
      0.4714,
      0.4716,
      0.4646,
      0.468,
      0.4638,
      0.4686,
      0.4746,
      0.4698,
      0.4672,
      0.467,
      0.4696,
      0.471,
      0.468,
      0.4642,
      0.4732,
      0.4718,
      0.471,
      0.4674,
      0.4708,
      0.477,
      0.468,
      0.4698,
      0.478,
      0.4728,
      0.4698,
      0.4682,
      0.4672,
      0.4728,
      0.472,
      0.4738,
      0.4712,
      0.4632,
      0.4704,
      0.4644,
      0.471,
      0.4738,
      0.475,
      0.4726,
      0.468,
      0.4722,
      0.465,
      0.476,
      0.4676,
      0.4736,
      0.4656,
      0.4728,
      0.4756,
      0.4674,
      0.4754,
      0.4678,
      0.47,
      0.4708,
      0.4712,
      0.4758,
      0.4722,
      0.4674,
      0.4704,
      0.4732,
      0.4712,
      0.47,
      0.4726,
      0.4648,
      0.4746,
      0.4788,
      0.4684,
      0.4658,
      0.4702,
      0.4696,
      0.4742,
      0.4672,
      0.4688,
      0.472,
      0.4622,
      0.4682,
      0.4768,
      0.465,
      0.4644,
      0.4684,
      0.468,
      0.4708,
      0.4704,
      0.4682,
      0.4732,
      0.468,
      0.4676,
      0.473,
      0.465,
      0.4646,
      0.4754,
      0.4692,
      0.4724,
      0.475,
      0.4644
    ],
    "final_val_accuracy": 0.4644,
    "best_val_accuracy": 0.4788
  }
}