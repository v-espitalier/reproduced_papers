# Main training script for Quantum Self-Supervised Learning (qSSL)
# This script implements the complete training pipeline for both classical and quantum SSL methods
# Based on "Quantum Self-Supervised Learning" by Jaderberg et al. (2022)

import argparse

import torch
import torch.nn as nn
from data_utils import load_finetuning_data, load_transformed_data
from model import QSSL
from torchsummary import summary
from training_utils import linear_evaluation, save_results_to_json, train

# Command-line argument parser for configuring the experiment
parser = argparse.ArgumentParser(description="PyTorch Quantum self-sup training")

# ========== Dataset Configuration ==========
parser.add_argument(
    "-d", "--datadir", metavar="DIR", default="./data", help="path to dataset"
)
parser.add_argument("-cl", "--classes", type=int, default=2, help="Number of classes")
# ========== Training Configuration ==========
parser.add_argument(
    "-e", "--epochs", type=int, default=2, help="Number of epochs for SSL pre-training"
)
parser.add_argument(
    "-le", "--le-epochs", type=int, default=100, help="Number of epochs for linear evaluation"
)
parser.add_argument("-bs", "--batch_size", type=int, default=128, help="Batch size")
# ========== SSL Model Configuration ==========
parser.add_argument(
    "-bn",
    "--batch_norm",
    action="store_true",
    default=False,
    help="Set if we use BatchNorm after compression of the encoder",
)
# ========== Contrastive Loss Configuration ==========
parser.add_argument(
    "-ld", "--loss_dim", type=int, default=128, help="Dimension of the loss space"
)
parser.add_argument(
    "-tau",
    "--temperature",
    type=float,
    default=0.07,
    help="Temperature parameter for InfoNCE loss (lower = harder negatives)",
)
# ========== Quantum SSL Configuration (MerLin) ==========
parser.add_argument(
    "-w",
    "--width",
    type=int,
    default=8,
    help="Dimension of the features encoded in the quantum neural network",
)
parser.add_argument(
    "--merlin",
    action="store_true",
    default=False,
    help="Use Quantum SSL with MerLin photonic framework",
)
parser.add_argument("-m", "--modes", type=int, default=10, help="Number of photonic modes in quantum circuit")
parser.add_argument(
    "-bunch",
    "--no_bunching",
    action="store_true",
    default=False,
    help="Disable photon bunching in quantum circuit",
)

# ========== Quantum SSL Configuration (Qiskit) ==========
# Based on implementation from https://github.com/bjader/QSSL
parser.add_argument(
    "--qiskit",
    action="store_true",
    default=False,
    help="Use Quantum SSL with Qiskit quantum computing framework",
)
parser.add_argument(
    "--layers",
    type=int,
    default=2,
    help="Number of layers in the test network (default: 2).",
)
parser.add_argument(
    "--q_backend",
    type=str,
    default="qasm_simulator",
    help="Type of backend simulator to run quantum circuits on (default: qasm_simulator)",
)

parser.add_argument(
    "--encoding",
    type=str,
    default="vector",
    help="Data encoding method (default: vector)",
)
parser.add_argument(
    "--q_ansatz",
    type=str,
    default="sim_circ_14_half",
    help="Variational ansatz method (default: sim_circ_14_half)",
)
parser.add_argument("--q_sweeps", type=int, default=1, help="Number of ansatz sweeeps.")
parser.add_argument(
    "--activation",
    type=str,
    default="null",
    help="Quantum layer activation function type (default: null)",
)
parser.add_argument(
    "--shots",
    type=int,
    default=100,
    help="Number of shots for quantum circuit evaluations.",
)
parser.add_argument(
    "--save-dhs",
    action="store_true",
    help="If enabled, compute the Hilbert-Schmidt distance of the quantum statevectors belonging to"
    " each class. Only works for -q and --classes 2.",
)


if __name__ == "__main__":
    args = parser.parse_args()

    # ========== Phase 1: Self-Supervised Learning ==========
    # Load SSL training data with heavy augmentations for contrastive learning
    train_dataset = load_transformed_data(args)
    print(f"\n Loaded SSL training dataset with {len(train_dataset)} samples")
    train_loader = torch.utils.data.DataLoader(
        train_dataset, batch_size=args.batch_size, shuffle=True
    )

    # Initialize the QSSL model (quantum or classical based on args)
    model = QSSL(args)
    # Display model architecture summary for two CIFAR-10 images (query and key)
    summary(model, [(3, 32, 32), (3, 32, 32)])
    print(
        f"Total trainable parameters in SSL model: {sum(p.numel() for p in model.parameters() if p.requires_grad)}"
    )

    # Train the SSL model using contrastive learning on augmented image pairs
    model, ssl_training_losses, results_dir = train(model, train_loader, args)

    # ========== Phase 2: Linear Evaluation ==========
    # Build model for linear evaluation with frozen feature extractor
    frozen_model = nn.Sequential(
        model.backbone,        # ResNet18 backbone (frozen)
        model.comp,           # Compression layer (frozen)
        model.representation_network,  # Quantum/classical rep network (frozen)
        nn.Linear(model.rep_net_output_size, args.classes),  # Linear classifier (trainable)
    )
    print(
        f"Trainable parameters in linear evaluation: {sum(p.numel() for p in frozen_model[2].parameters() if p.requires_grad) + sum(p.numel() for p in frozen_model[-1].parameters() if p.requires_grad)}"
    )
    # Freeze all layers except the final linear classifier
    frozen_model.requires_grad_(False)
    frozen_model[-1].requires_grad_(True)

    # Load linear evaluation data with minimal augmentations
    train_dataset, eval_dataset = load_finetuning_data(args)
    print(f"\n Loaded linear evaluation datasets: {len(train_dataset)} train, {len(eval_dataset)} validation")
    train_loader = torch.utils.data.DataLoader(
        train_dataset, batch_size=args.batch_size, shuffle=True
    )
    val_loader = torch.utils.data.DataLoader(
        eval_dataset, batch_size=args.batch_size, shuffle=True
    )

    # Perform linear evaluation to assess quality of learned representations
    model, ft_train_losses, ft_val_losses, ft_train_accs, ft_val_accs = (
        linear_evaluation(frozen_model, train_loader, val_loader, args, results_dir)
    )

    # ========== Save Experiment Results ==========
    # Save comprehensive results including SSL losses and linear evaluation metrics
    save_results_to_json(
        args,
        ssl_training_losses,
        ft_train_losses,
        ft_val_losses,
        ft_train_accs,
        ft_val_accs,
        results_dir,
    )
